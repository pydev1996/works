{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32d5bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import PorterStemmer, WordNetLemmatizer\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pyttsx3\n",
    "import speech_recognition as sr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d87f505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "938790be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality():\n",
    "    col=df.columns.tolist()\n",
    "    misingvaluescount=df.isna().sum().values.tolist()\n",
    "    return col,misingvaluescount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa2f10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve():\n",
    "    global df\n",
    "    df.sort_values(\"age\", inplace=True)\n",
    "    df=df.drop_duplicates()\n",
    "    df=df.drop(['education', 'marital.status','native.country','occupation','relationship','race'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "355cad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statstic():\n",
    "    d=df.describe()\n",
    "    di=df['income'].argmax()\n",
    "    dc=df['income'].value_counts()\n",
    "    return d,di,dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9fde294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    labelencoder = LabelEncoder()\n",
    "    df['workclass'] = labelencoder.fit_transform(df['workclass'])\n",
    "    df['sex'] = labelencoder.fit_transform(df['sex'])\n",
    "    x=df.iloc[:,:8]\n",
    "    y=df.iloc[:,8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.25, random_state= 0)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e45f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(X_train,Y_train):\n",
    "  lr=LinearRegression()\n",
    "  lr.fit(X_train,Y_train)\n",
    "  svm = SVC(kernel= 'linear', C = 1).fit(X_train, y_train)\n",
    "  #Using RandomForestClassifier()\n",
    "  rf=RandomForestClassifier()\n",
    "  rf.fit(X_train,Y_train)\n",
    "   #Using KNeighborsClassifier \n",
    "  knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "  knn.fit(X_train, Y_train)\n",
    "\n",
    "  #Using DecisionTreeClassifier \n",
    "  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "  tree.fit(X_train, Y_train)\n",
    "    \n",
    "  \n",
    "  #print model accuracy on the training data.\n",
    "  print('[1]K Nearest Neighbor Training Accuracy:', knn.score(X_train, Y_train))\n",
    "  print('[2]Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))\n",
    "  print('[3]Random Forest Classifier Training Accuracy:', rf.score(X_train, Y_train))\n",
    "  print('[4]SVM Classifier Training Accuracy:', svm.score(X_train, Y_train))\n",
    "  print('[5]LinearRegression Classifier Training Accuracy:', lr.score(X_train, Y_train))\n",
    "  \n",
    "  \n",
    "  \n",
    "  return  lr,svm,rf,knn,tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76ba32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix():\n",
    "    for i in model:\n",
    "          try:\n",
    "              cm = confusion_matrix(y_test, i.predict(X_test))\n",
    "\n",
    "              TN = cm[0][0]\n",
    "              TP = cm[1][1]\n",
    "              FN = cm[1][0]\n",
    "              FP = cm[0][1]\n",
    "\n",
    "              print(cm)\n",
    "              print('Model[{}] Testing Accuracy = \"{}!\"'.format(i,  (TP + TN) / (TP + TN + FN + FP)))\n",
    "          except:\n",
    "            pass\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be6a4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrix(model):\n",
    "    for i in range(len(model)):\n",
    "          try:\n",
    "              print('Model ',i)\n",
    "              #Check precision, recall, f1-score\n",
    "              print( classification_report(y_test, model[i].predict(X_test)) )\n",
    "              #Another way to get the models accuracy on the test data\n",
    "              print( accuracy_score(y_test, model[i].predict(X_test)))\n",
    "              print()#Print a new line\n",
    "          except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "075617f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validations(model):\n",
    "    pred_k = model[-1].predict(X_test)\n",
    "    print(pred_k)\n",
    "   \n",
    "    #Print a space\n",
    "    print()\n",
    "\n",
    "    #Print the actual values\n",
    "    print(y_test)\n",
    "    return pred_k,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6342a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(model):\n",
    "    pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0456ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak\n",
      "Recognizing...\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.88687539,\n",
      "                           'transcript': 'classification model'},\n",
      "                       {'transcript': 'special model'},\n",
      "                       {'transcript': 'model'},\n",
      "                       {'transcript': 'class model'}],\n",
      "    'final': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_11924\\600648636.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train,Y_train)\n",
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]K Nearest Neighbor Training Accuracy: 0.8657487091222031\n",
      "[2]Decision Tree Classifier Training Accuracy: 0.9993443160396689\n",
      "[3]Random Forest Classifier Training Accuracy: 0.9993443160396689\n",
      "[4]SVM Classifier Training Accuracy: 0.8114089009097615\n",
      "[5]LinearRegression Classifier Training Accuracy: 0.25050029457188294\n"
     ]
    }
   ],
   "source": [
    "def speech_text():\n",
    "        r = sr.Recognizer()\n",
    "        print(\"speak\")\n",
    "        with sr.Microphone() as source:\n",
    "\n",
    "            audio_data = r.record(source, duration=5)\n",
    "            print(\"Recognizing...\")\n",
    "            n = r.recognize_google(audio_data)\n",
    "            #print(n)\n",
    "            if n=='quality':\n",
    "                c,m=quality()\n",
    "                print(c)\n",
    "            elif n=='improve':\n",
    "                improve()\n",
    "                print(\"Succesfully Remove Dupliactes and Unwanted Columns in dataset\")\n",
    "            elif n=='analyse':\n",
    "                d,di,dc=statstic()\n",
    "                print(d)\n",
    "            elif n=='split':\n",
    "                split_data()\n",
    "                print(\"Succesfully Split the data into testing and traing\")\n",
    "            elif n==\"classification model\":\n",
    "                X_train, X_test, y_train, y_test=split_data()\n",
    "                models(X_train,y_train)\n",
    "            elif n==\"accuracy\":\n",
    "                X_train, X_test, y_train, y_test=split_data()\n",
    "                \n",
    "                lr,svm,rf,knn,tree=models(X_train,y_train)\n",
    "            elif n==\"cross validation\":\n",
    "                X_train, X_test, y_train, y_test=split_data()\n",
    "                \n",
    "                lr,svm,rf,knn,tree=models(X_train,y_train)\n",
    "                cross_validations(model)\n",
    "                \n",
    "speech_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829cecb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
